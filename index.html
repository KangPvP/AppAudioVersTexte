<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Speech to Text - Google Cloud (Universel)</title>
    <style>
        body { font-family: sans-serif; padding: 20px; max-width: 800px; margin: 0 auto; }
        .container { border: 1px solid #ccc; padding: 20px; border-radius: 8px; }
        textarea { width: 100%; height: 150px; margin-top: 10px; }
        button { padding: 10px 20px; cursor: pointer; background-color: #007bff; color: white; border: none; border-radius: 4px; font-size: 16px; }
        button:disabled { background-color: #ccc; cursor: not-allowed; }
        .status { margin-top: 10px; color: #555; font-weight: bold; }
        .error { color: red; }
    </style>
</head>
<body>

<div class="container">
    <h2>Reconnaissance Vocale (M4A, MP3, WAV...)</h2>
    <p>Sélectionnez un fichier audio (max ~1 min pour éviter le timeout).</p>
    
    <input type="file" id="audioInput" accept="audio/*">
    <br><br>
    
    <button id="sendBtn">Transcrire l'audio</button>
    
    <div id="status" class="status"></div>
    
    <h3>Résultat :</h3>
    <textarea id="resultOutput" placeholder="Le texte apparaîtra ici..."></textarea>
</div>

<script>
    // ⚠️ REMPLACEZ CECI PAR VOTRE CLÉ API
    // Note : En production, ne laissez jamais cette clé ici, passez par un serveur backend.
    const API_KEY = 'AIzaSyDvhEEI4Nb7yo1b1RRwitaU9Y7JpgguTUY'; 

    const statusDiv = document.getElementById('status');
    const resultOutput = document.getElementById('resultOutput');
    const sendBtn = document.getElementById('sendBtn');

    sendBtn.addEventListener('click', async () => {
        const inputElement = document.getElementById('audioInput');

        if (inputElement.files.length === 0) {
            alert("Veuillez sélectionner un fichier d'abord.");
            return;
        }

        const file = inputElement.files[0];
        
        // Reset UI
        resultOutput.value = "";
        statusDiv.className = "status";
        statusDiv.textContent = "1/4. Lecture et décodage du fichier audio...";
        sendBtn.disabled = true;

        try {
            // ÉTAPE 1 : Conversion universelle en WAV (LINEAR16)
            // Cela gère le M4A, le MP3, et récupère le bon SampleRate
            const audioData = await convertFileToWavBase64(file);

            statusDiv.textContent = `2/4. Fichier converti en WAV (${audioData.sampleRate}Hz). Envoi à Google...`;

            // ÉTAPE 2 : Préparation de la requête Google
            const payload = {
                config: {
                    encoding: "LINEAR16", // On force LINEAR16 car on vient de convertir en WAV
                    sampleRateHertz: audioData.sampleRate, // La fréquence exacte issue du décodage
                    languageCode: "fr-FR",
                    enableAutomaticPunctuation: true,
                    model: "default"
                },
                audio: {
                    content: audioData.base64
                }
            };

            // ÉTAPE 3 : Appel API Fetch
            const response = await fetch(`https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(payload)
            });

            const data = await response.json();

            // ÉTAPE 4 : Gestion du résultat
            statusDiv.textContent = "Terminé.";
            
            if (data.error) {
                throw new Error(`Erreur API Google (${data.error.code}): ${data.error.message}`);
            }

            if (data.results) {
                const transcript = data.results
                    .map(result => result.alternatives[0].transcript)
                    .join('\n');
                resultOutput.value = transcript;
            } else {
                resultOutput.value = "(Aucune parole détectée ou audio trop silencieux)";
            }

        } catch (error) {
            console.error(error);
            statusDiv.textContent = "Erreur : " + error.message;
            statusDiv.className = "status error";
        } finally {
            sendBtn.disabled = false;
        }
    });

    // ==========================================
    // FONCTIONS UTILITAIRES DE CONVERSION (MOTEUR)
    // ==========================================

    /**
     * Prend un fichier (Blob), le décode en AudioBuffer, 
     * le convertit en WAV PCM 16-bit, et retourne le Base64 + SampleRate.
     */
    async function convertFileToWavBase64(file) {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        try {
            const arrayBuffer = await file.arrayBuffer();
            // Décodage natif du navigateur (gère MP3, AAC/M4A, OGG...)
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            
            // Conversion RAW -> WAV
            const wavBlob = bufferToWav(audioBuffer);
            
            // Blob -> Base64
            const base64 = await blobToBase64(wavBlob);

            return {
                base64: base64,
                sampleRate: audioBuffer.sampleRate
            };
        } finally {
            // Toujours fermer le contexte pour libérer la mémoire
            if (audioContext.state !== 'closed') {
                audioContext.close();
            }
        }
    }

    // Convertit un Blob en chaîne Base64 pure (sans l'en-tête "data:audio/...")
    function blobToBase64(blob) {
        return new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.readAsDataURL(blob);
            reader.onload = () => {
                const base64String = reader.result.split(',')[1];
                resolve(base64String);
            };
            reader.onerror = reject;
        });
    }

    // Convertit un AudioBuffer en fichier WAV (Blob)
    // Algorithme standard pour écrire les en-têtes RIFF WAVE
    function bufferToWav(abuffer) {
        const numOfChan = abuffer.numberOfChannels;
        const length = abuffer.length * numOfChan * 2 + 44;
        const buffer = new ArrayBuffer(length);
        const view = new DataView(buffer);
        const channels = [];
        let i, sample;
        let offset = 0;
        let pos = 0;

        // Fonction helper pour écrire des chaînes
        function setUint32(data) { view.setUint32(pos, data, true); pos += 4; }
        function setUint16(data) { view.setUint16(pos, data, true); pos += 2; }

        // 1. Écriture en-tête RIFF
        setUint32(0x46464952); // "RIFF"
        setUint32(length - 8); // taille fichier - 8
        setUint32(0x45564157); // "WAVE"

        // 2. Écriture en-tête fmt
        setUint32(0x20746d66); // "fmt "
        setUint32(16);         // longueur PCM
        setUint16(1);          // Audio format (1 = PCM)
        setUint16(numOfChan);
        setUint32(abuffer.sampleRate);
        setUint32(abuffer.sampleRate * 2 * numOfChan); // byte rate
        setUint16(numOfChan * 2); // block align
        setUint16(16);            // bits per sample

        // 3. Écriture en-tête data
        setUint32(0x61746164); // "data"
        setUint32(length - pos - 4); // taille chunk data

        // 4. Écriture des données audio (entrelacées)
        for(i = 0; i < abuffer.numberOfChannels; i++)
            channels.push(abuffer.getChannelData(i));

        while(pos < length) {
            for(i = 0; i < numOfChan; i++) {
                // Le sample est entre -1 et 1 (float), on le convertit en Int16
                sample = Math.max(-1, Math.min(1, channels[i][offset])); 
                sample = (sample < 0 ? sample * 0x8000 : sample * 0x7FFF) | 0;
                view.setInt16(pos, sample, true); 
                pos += 2;
            }
            offset++;
        }

        return new Blob([buffer], { type: "audio/wav" });
    }
</script>

</body>
</html>